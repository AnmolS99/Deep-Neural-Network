; Neural network with two hidden layers that uses MSE as loss function
[globals]
loss: mse
include_softmax: false
num_classes: 4
regularizer: l1
reg_rate: 0.001
epochs: 100
batch_size: 7

[data_generator]
image_dimension: 20
dataset_size: 200
l_lower_frac: 0.20
l_higher_frac: 0.40
width_lower_frac: 0.02
width_higher_frac: 0.04
centering: False
noise_percentage: 0.01
train_frac: 0.70
valid_frac: 0.20
test_frac: 0.10

[layer_1]
neurons: 75
activation_function: relu
wr_lower: -0.5
wr_higher:  0.5
lr: 0.1

[layer_2]
neurons: 75
activation_function: relu
wr_lower: -0.5
wr_higher: 0.5
lr: 0.1

[layer_3]
neurons: 4
activation_function: sigmoid
wr_lower: -0.5
wr_higher: 0.5
lr: 0.1